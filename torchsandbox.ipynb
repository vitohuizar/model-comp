{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008220434188842773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140da6c1ecb54d1f8be4b721b34c521a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007899284362792969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6123df26f1a43308cae29e14680d3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008348226547241211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3ed425d641448fb1566840d1ebd9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007941007614135742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108672227e224a199dcd77f966649690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets. \n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    "    )\n",
    "\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# ~~ Model ~~\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        input = 28*28\n",
    "        hidden = 512\n",
    "        output = 10\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, output)\n",
    "        )\n",
    "\n",
    "    # Forward Pass\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "# Test Loop\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.245683  [    0/60000]\n",
      "loss: 2.248158  [ 6400/60000]\n",
      "loss: 2.247702  [12800/60000]\n",
      "loss: 2.248788  [19200/60000]\n",
      "loss: 2.248897  [25600/60000]\n",
      "loss: 2.251332  [32000/60000]\n",
      "loss: 2.237065  [38400/60000]\n",
      "loss: 2.253375  [44800/60000]\n",
      "loss: 2.238450  [51200/60000]\n",
      "loss: 2.262363  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 2.226839 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.217195  [    0/60000]\n",
      "loss: 2.229361  [ 6400/60000]\n",
      "loss: 2.202537  [12800/60000]\n",
      "loss: 2.218936  [19200/60000]\n",
      "loss: 2.207987  [25600/60000]\n",
      "loss: 2.225086  [32000/60000]\n",
      "loss: 2.225024  [38400/60000]\n",
      "loss: 2.208313  [44800/60000]\n",
      "loss: 2.184345  [51200/60000]\n",
      "loss: 2.174157  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 2.184050 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.205744  [    0/60000]\n",
      "loss: 2.198678  [ 6400/60000]\n",
      "loss: 2.169452  [12800/60000]\n",
      "loss: 2.145407  [19200/60000]\n",
      "loss: 2.148461  [25600/60000]\n",
      "loss: 2.176127  [32000/60000]\n",
      "loss: 2.177439  [38400/60000]\n",
      "loss: 2.125789  [44800/60000]\n",
      "loss: 2.086870  [51200/60000]\n",
      "loss: 2.069729  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 2.115042 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.111406  [    0/60000]\n",
      "loss: 2.149391  [ 6400/60000]\n",
      "loss: 2.067948  [12800/60000]\n",
      "loss: 2.138337  [19200/60000]\n",
      "loss: 2.100331  [25600/60000]\n",
      "loss: 2.043847  [32000/60000]\n",
      "loss: 2.048918  [38400/60000]\n",
      "loss: 1.968906  [44800/60000]\n",
      "loss: 2.001848  [51200/60000]\n",
      "loss: 2.011394  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 2.011315 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.937971  [    0/60000]\n",
      "loss: 2.056311  [ 6400/60000]\n",
      "loss: 2.024395  [12800/60000]\n",
      "loss: 1.949514  [19200/60000]\n",
      "loss: 1.934434  [25600/60000]\n",
      "loss: 1.846497  [32000/60000]\n",
      "loss: 2.023793  [38400/60000]\n",
      "loss: 1.929813  [44800/60000]\n",
      "loss: 1.959437  [51200/60000]\n",
      "loss: 1.912007  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 1.866387 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.863065  [    0/60000]\n",
      "loss: 1.772029  [ 6400/60000]\n",
      "loss: 1.882886  [12800/60000]\n",
      "loss: 1.843064  [19200/60000]\n",
      "loss: 1.851829  [25600/60000]\n",
      "loss: 1.769685  [32000/60000]\n",
      "loss: 1.738014  [38400/60000]\n",
      "loss: 1.776387  [44800/60000]\n",
      "loss: 1.596476  [51200/60000]\n",
      "loss: 1.748520  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 1.667883 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.684782  [    0/60000]\n",
      "loss: 1.660313  [ 6400/60000]\n",
      "loss: 1.623632  [12800/60000]\n",
      "loss: 1.576870  [19200/60000]\n",
      "loss: 1.589575  [25600/60000]\n",
      "loss: 1.497167  [32000/60000]\n",
      "loss: 1.519907  [38400/60000]\n",
      "loss: 1.466727  [44800/60000]\n",
      "loss: 1.548973  [51200/60000]\n",
      "loss: 1.547584  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.443268 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.392801  [    0/60000]\n",
      "loss: 1.396808  [ 6400/60000]\n",
      "loss: 1.479828  [12800/60000]\n",
      "loss: 1.410940  [19200/60000]\n",
      "loss: 1.476859  [25600/60000]\n",
      "loss: 1.288014  [32000/60000]\n",
      "loss: 1.340024  [38400/60000]\n",
      "loss: 1.213083  [44800/60000]\n",
      "loss: 1.329890  [51200/60000]\n",
      "loss: 1.413254  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 1.257828 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.218551  [    0/60000]\n",
      "loss: 1.337345  [ 6400/60000]\n",
      "loss: 1.223568  [12800/60000]\n",
      "loss: 1.196184  [19200/60000]\n",
      "loss: 1.104532  [25600/60000]\n",
      "loss: 1.129850  [32000/60000]\n",
      "loss: 1.262222  [38400/60000]\n",
      "loss: 1.161477  [44800/60000]\n",
      "loss: 0.964665  [51200/60000]\n",
      "loss: 1.068563  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.120520 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.203496  [    0/60000]\n",
      "loss: 1.211741  [ 6400/60000]\n",
      "loss: 0.902784  [12800/60000]\n",
      "loss: 1.150648  [19200/60000]\n",
      "loss: 1.183013  [25600/60000]\n",
      "loss: 1.000125  [32000/60000]\n",
      "loss: 1.097241  [38400/60000]\n",
      "loss: 0.951681  [44800/60000]\n",
      "loss: 1.081202  [51200/60000]\n",
      "loss: 1.122293  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.008461 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.193675  [    0/60000]\n",
      "loss: 1.108264  [ 6400/60000]\n",
      "loss: 1.002043  [12800/60000]\n",
      "loss: 1.006429  [19200/60000]\n",
      "loss: 1.026831  [25600/60000]\n",
      "loss: 0.945576  [32000/60000]\n",
      "loss: 0.938247  [38400/60000]\n",
      "loss: 0.875873  [44800/60000]\n",
      "loss: 0.958095  [51200/60000]\n",
      "loss: 0.817334  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.905129 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.833941  [    0/60000]\n",
      "loss: 0.872523  [ 6400/60000]\n",
      "loss: 0.960967  [12800/60000]\n",
      "loss: 0.669307  [19200/60000]\n",
      "loss: 1.109979  [25600/60000]\n",
      "loss: 0.847129  [32000/60000]\n",
      "loss: 0.924961  [38400/60000]\n",
      "loss: 0.940693  [44800/60000]\n",
      "loss: 0.867514  [51200/60000]\n",
      "loss: 0.978866  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.806838 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.740918  [    0/60000]\n",
      "loss: 0.796809  [ 6400/60000]\n",
      "loss: 0.746656  [12800/60000]\n",
      "loss: 0.708167  [19200/60000]\n",
      "loss: 0.771839  [25600/60000]\n",
      "loss: 0.647469  [32000/60000]\n",
      "loss: 0.773838  [38400/60000]\n",
      "loss: 0.727307  [44800/60000]\n",
      "loss: 0.849226  [51200/60000]\n",
      "loss: 0.739861  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.718659 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.878770  [    0/60000]\n",
      "loss: 0.831156  [ 6400/60000]\n",
      "loss: 0.686837  [12800/60000]\n",
      "loss: 0.625188  [19200/60000]\n",
      "loss: 0.763067  [25600/60000]\n",
      "loss: 0.819400  [32000/60000]\n",
      "loss: 0.649872  [38400/60000]\n",
      "loss: 0.857201  [44800/60000]\n",
      "loss: 0.706238  [51200/60000]\n",
      "loss: 0.911880  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.644820 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.662792  [    0/60000]\n",
      "loss: 0.683864  [ 6400/60000]\n",
      "loss: 0.617545  [12800/60000]\n",
      "loss: 0.711339  [19200/60000]\n",
      "loss: 0.502274  [25600/60000]\n",
      "loss: 0.490682  [32000/60000]\n",
      "loss: 0.580359  [38400/60000]\n",
      "loss: 0.656324  [44800/60000]\n",
      "loss: 0.573280  [51200/60000]\n",
      "loss: 0.722982  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.587123 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.523366  [    0/60000]\n",
      "loss: 0.407940  [ 6400/60000]\n",
      "loss: 0.547269  [12800/60000]\n",
      "loss: 0.518375  [19200/60000]\n",
      "loss: 0.565613  [25600/60000]\n",
      "loss: 0.621857  [32000/60000]\n",
      "loss: 0.575322  [38400/60000]\n",
      "loss: 0.530868  [44800/60000]\n",
      "loss: 0.610749  [51200/60000]\n",
      "loss: 0.584466  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.545107 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.733407  [    0/60000]\n",
      "loss: 0.522572  [ 6400/60000]\n",
      "loss: 0.482957  [12800/60000]\n",
      "loss: 0.511849  [19200/60000]\n",
      "loss: 0.731093  [25600/60000]\n",
      "loss: 0.461431  [32000/60000]\n",
      "loss: 0.593876  [38400/60000]\n",
      "loss: 0.419219  [44800/60000]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/minimaster/fun/torch/torchsandbox.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/minimaster/fun/torch/torchsandbox.ipynb Cell 9\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/minimaster/fun/torch/torchsandbox.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Compute prediction and loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.10/site-packages/torchvision/transforms/functional.py:164\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    163\u001b[0m mode_to_nptype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint16, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m--> 164\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39;49marray(pic, mode_to_nptype\u001b[39m.\u001b[39;49mget(pic\u001b[39m.\u001b[39;49mmode, np\u001b[39m.\u001b[39;49muint8), copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'Image'"
     ]
    }
   ],
   "source": [
    "# Epochs\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loop(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "    print(\"Saved Model State to model.pth\")\n",
    "except KeyboardInterrupt:\n",
    "    # Save model training progress. \n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "    print(\"Saved Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bf58aa1641f7cf2c465fa4a93fced32c44aa2a9db57a360140dc5fbde249e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
